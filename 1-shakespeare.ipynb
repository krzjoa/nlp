{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e97688e6",
   "metadata": {},
   "source": [
    "# Generating Shakespeare poetry with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dc2d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torchtext\n",
    "# !pip3 install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b244b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.transforms import VocabTransform\n",
    "# We only need TF to dowaload the file - an useful function is available in keras\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# import ipdb\n",
    "\n",
    "# TF: https://www.tensorflow.org/text/tutorials/text_generation\n",
    "# https://www.kdnuggets.com/2020/07/pytorch-lstm-text-generation-tutorial.html\n",
    "# https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html\n",
    "# https://pytorch.org/docs/stable/quantization.html#torch.quantization.quantize_dynamic\n",
    "# https://anie.me/On-Torchtext/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31675b4c",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd7d633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the file with Shakespare poetry\n",
    "path_to_file = tf.keras.utils.get_file(\n",
    "    'shakespeare.txt', \n",
    "    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ec6e5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/krzysztof/.keras/datasets/shakespeare.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ad0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(path_to_file, 'rb').read()\n",
    "text = text.decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36f960",
   "metadata": {},
   "source": [
    "## Unique tokens\n",
    "We assume the atomic token of the text is a letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ccfdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = sorted(set(text))\n",
    "letters = OrderedDict([(i, 1) for i in letters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3769790",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vocab(letters)\n",
    "vocab_transform = VocabTransform(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71d527f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary.vocab.itos_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e9d92",
   "metadata": {},
   "source": [
    "## Splitting text by letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00912387",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_text = list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5edfb310",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = vocab_transform(splitted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dca889",
   "metadata": {},
   "source": [
    "## Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddfbadbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyShakespeare(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_letters, embedding_dim = 15, hidden_size = 32):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(n_letters, embedding_dim=embedding_dim)\n",
    "        self.rnn = nn.LSTM(input_size = embedding_dim, hidden_size = hidden_size)\n",
    "        self.final_layer = nn.Linear(hidden_size, n_letters)\n",
    "        self.softmax = nn.Softmax(-1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # ipdb.set_trace()\n",
    "        rnn_output, _ = self.rnn(self.embed(input))\n",
    "        last_vec = rnn_output[:,-1, :]\n",
    "        final_output = self.final_layer(last_vec) \n",
    "        return self.softmax(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50ff872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_shakespeare = TinyShakespeare(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3fffb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = torch.tensor([1, 10, 56]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4b36c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0167, 0.0150, 0.0142, 0.0183, 0.0171, 0.0151, 0.0135, 0.0146, 0.0142,\n",
       "         0.0142, 0.0163, 0.0134, 0.0168, 0.0139, 0.0173, 0.0161, 0.0145, 0.0143,\n",
       "         0.0169, 0.0164, 0.0151, 0.0171, 0.0132, 0.0158, 0.0137, 0.0154, 0.0157,\n",
       "         0.0171, 0.0135, 0.0143, 0.0170, 0.0147, 0.0133, 0.0143, 0.0177, 0.0150,\n",
       "         0.0143, 0.0167, 0.0151, 0.0177, 0.0146, 0.0155, 0.0176, 0.0149, 0.0134,\n",
       "         0.0151, 0.0156, 0.0126, 0.0152, 0.0167, 0.0132, 0.0176, 0.0161, 0.0162,\n",
       "         0.0162, 0.0140, 0.0149, 0.0178, 0.0155, 0.0135, 0.0139, 0.0173, 0.0140,\n",
       "         0.0175, 0.0155]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_shakespeare(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bd13427",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoetrySchool(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss_fun = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def training_step(self, batch_size, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self.model(x)\n",
    "        loss = self.loss_fun(output, y)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad537bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry_school = PoetrySchool(tiny_shakespeare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72fbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoetryDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
